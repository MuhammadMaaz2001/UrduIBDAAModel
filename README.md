# UrduIBDAAModel
Training a Large Corpus Urdu Dataset For Paraphrasing on MT5 Conditional Generation

Paraphrasing is a fundamental task in natural language processing, and it is particularly
challenging for low-resource languages like Urdu. In this research, we present an approach to
improving the performance of paraphrase generation models for Urdu using
transformer-based architectures. We leverage a large-scale Urdu dataset and utilized the
ability of a pre-trained model, MT5ForConditionalGeneration, to adapt it to the paraphrasing
task. Our model, UrduIbdaa, is evaluated on standard metrics and compared with existing
approaches. The results demonstrate that UrduIbdaa achieves state-of-the-art performance,
indicating its effectiveness in generating high-quality paraphrases in Urdu. We also provide a
comprehensive analysis of the model's performance, including the impact of different model
sizes and the importance of dataset quality. The code, models, and datasets used in this
research are made publicly available to facilitate further research and development in Urdu
language processing.


Reference link :
https://figshare.com/articles/preprint/Training_a_Large_Corpus_Urdu_Dataset_For_Paraphrasing_on_MT5_Conditional_Generation/26318086/1?file=47738821
